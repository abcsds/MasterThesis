%!TEX root = ../thesis.tex

https://texfaq.org/FAQ-appendix

List of Atom packages used
├── Hydrogen@2.14.1
├── atom-beautify@0.33.4
├── autocomplete-bibtex@1.2.10
├── autocomplete-python@1.16.0
├── color-picker@2.3.0
├── docker@0.8.0
├── ide-python@1.5.0
├── jekyll@2.1.0
├── language-csv@1.1.2
├── language-docker@1.1.8
├── language-latex@1.2.0
├── language-liquid@0.7.0
├── latex@0.50.2
├── latex-autocomplete@1.1.1
├── latex-hyperclick@0.2.0
├── linter@2.3.1
├── linter-chktex@1.4.0
├── linter-flake8@2.4.0
├── linter-ui-default@1.8.1
├── pdf-view@0.72.0
├── python-tools@0.6.9
├── set-syntax@0.4.0
├── sort-lines@0.19.0
├── split-diff@1.6.1
└── zotero-picker@2.0.2


Python libraries used
bokeh==2.0.1
en-core-web-sm==2.2.5
fastcluster==1.1.26
fasttext==0.9.1
flake8==3.7.9
gensim==3.8.1
ipython==7.13.0
jupyter==1.0.0
matplotlib==3.2.0
MulticoreTSNE==0.1
nbconvert==5.6.1
notebook==6.0.3
numpy==1.18.1
pandas==1.0.1
pandocfilters==1.4.2
Pillow==7.0.0
pycuda==2019.1.2
pyflakes==2.1.1
Pygments==2.6.1
pylint==2.4.4
python-language-server==0.31.8
scikit-learn==0.22.2.post1
scipy==1.4.1
seaborn==0.10.0
sentencepiece==0.1.85
sklearn==0.0
snowballstemmer==2.0.0
spacy==2.2.4
tokenizers==0.5.2
torch==1.4.0
torchvision==0.5.0
transformers==2.7.0
tsnecuda==0.1.1


CUDA library:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Wed_Oct_23_19:24:38_PDT_2019
Cuda compilation tools, release 10.2, V10.2.89


Ablative study: Why there isn't a one to one correlation between embedded dimensions and labels?
It's exactly what happens with feature maps. Why not with SLP? Use fasttext to explain the difference


% TODO: this table comes from klinger2018analysis
\begin{table}
    \centering
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
    \hline
        Dataset & Author & Year & License & Description & Format & Size & Emotion categories \\ \hline
        affectivetext & Strapparava \& Mihalcea & 2007 &  & Classification of emotions in news headlines & SGML/txt & 250 headlines & anger, disgust, fear, joy, sadnees, surprise, V \\ \hline
        crowdflower\_data & CrowdFlower & 2016 & available to download & Annotated dataset of tweets via crowdsourcing. & csv & 40k tweets & anger, enthusiasm, fun, happiness, hate, neutral, sadness, surprise, worry, love, boredom, worry, relief, empty \\ \hline
        dailydialog & Li Yanrand et al & 2017 & available to download & Manually labelled conversations dataset with topics and emotions & text & 13k dialogs & anger, disgust, fear, joy, sadness, surprise \\ \hline
        emotion-cause & Diman Ghazi\&Diana Inkpen\&Stan Szpakowicz & 2015 & research only & Automatically built dataset annotated with emotion and the stimulus using FrameNet’s emotions-directed frame & XML & 820 sents + 1594 sents & anger, sad, happy, surprise, fear, disgust \\ \hline
        EmoBank & Sven Buechel & 2017 & redistributable CC-BY 4.0 & Large-scale corpus annotated with emotion according to  VAD scheme & text & 10k & VAD \\ \hline
        emotiondata-aman & Saima Aman\&Stan Szpakowicz & 2007 & obtainable upon request & Manually annotated corpus with emotion categories. The agreement on emotion categories was \~0.66. & text & \~15k sents & joy, neutral, disgust, sadness, surprise, fear, anger \\ \hline
        fb-valence-arousal-annon & Preotiuc Pietro & 2016 & available to download & description & csv & 2.8k posts & VA \\ \hline
        grounded\_emotions & Liu, V.\&Banea, C.\&Mihalcea & 2017 & available to download & They look into wheter the effect of weather, news events, relates to the tweet sentiment & text & 2.5k tweets & joy, sadness \\ \hline
        isear & Klaus R. Scherer and Harald Wallbott & 1990 & available to download & reported situations in which emotions were experienced & text (mdb/sav) & 3000 docs & joy, fear, anger, sadness, disgust,shame, guilt \\ \hline
        tales-emotions & Cecilia Ovesdotter Alm & 2005 & gplv3 & Dataset of manually annotated tales used in a document classification task & text & 15k sents & angry, disgusted, fearful, happy, sad, surprised, mood (positive, negative) \\ \hline
        emoint &  &  &  &  &  &  &  \\ \hline
        electoraltweets &  &  &  &  &  &  &  \\ \hline
    \end{tabular}
\end{table}



Followed by equation~\ref{eq:equation_placeholder}
\begin{equation} \label{eq:equation_placeholder}
  \begin{split}
    A = \{&'a':['d','e','f','g'], \\
         &'b':['d','e','f','g'], \\
         &'c':['d','e','f','g'], \\
         &'d':['h'], \\
         &'e':['h'], \\
         &'f':['h'], \\
         &'g':['h'], \\
         &'h':[] \}
  \end{split}
\end{equation}
